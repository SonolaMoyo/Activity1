{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('NFA 2019 public_data.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>country_code</th>\n",
       "      <th>record</th>\n",
       "      <th>crop_land</th>\n",
       "      <th>grazing_land</th>\n",
       "      <th>forest_land</th>\n",
       "      <th>fishing_ground</th>\n",
       "      <th>built_up_land</th>\n",
       "      <th>carbon</th>\n",
       "      <th>total</th>\n",
       "      <th>QScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>AreaPerCap</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.199546</td>\n",
       "      <td>0.097188051</td>\n",
       "      <td>0.036888</td>\n",
       "      <td>0.029320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.032351e-01</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>AreaTotHA</td>\n",
       "      <td>483000.000000</td>\n",
       "      <td>687000.000000</td>\n",
       "      <td>334600</td>\n",
       "      <td>127000.000000</td>\n",
       "      <td>100943.000800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.732543e+06</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>BiocapPerCap</td>\n",
       "      <td>0.159804</td>\n",
       "      <td>0.135261</td>\n",
       "      <td>0.084003213</td>\n",
       "      <td>0.013742</td>\n",
       "      <td>0.033398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.262086e-01</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>BiocapTotGHA</td>\n",
       "      <td>550176.242700</td>\n",
       "      <td>465677.972200</td>\n",
       "      <td>289207.1078</td>\n",
       "      <td>47311.551720</td>\n",
       "      <td>114982.279300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.467355e+06</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>EFConsPerCap</td>\n",
       "      <td>0.387510</td>\n",
       "      <td>0.189462</td>\n",
       "      <td>1.26E-06</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.033398</td>\n",
       "      <td>1.114093</td>\n",
       "      <td>1.728629e+00</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  year  country_code        record      crop_land   grazing_land  \\\n",
       "0  Armenia  1992             1    AreaPerCap       0.140292       0.199546   \n",
       "1  Armenia  1992             1     AreaTotHA  483000.000000  687000.000000   \n",
       "2  Armenia  1992             1  BiocapPerCap       0.159804       0.135261   \n",
       "3  Armenia  1992             1  BiocapTotGHA  550176.242700  465677.972200   \n",
       "4  Armenia  1992             1  EFConsPerCap       0.387510       0.189462   \n",
       "\n",
       "   forest_land  fishing_ground  built_up_land    carbon         total QScore  \n",
       "0  0.097188051        0.036888       0.029320  0.000000  5.032351e-01     3A  \n",
       "1       334600   127000.000000  100943.000800  0.000000  1.732543e+06     3A  \n",
       "2  0.084003213        0.013742       0.033398  0.000000  4.262086e-01     3A  \n",
       "3  289207.1078    47311.551720  114982.279300  0.000000  1.467355e+06     3A  \n",
       "4     1.26E-06        0.004165       0.033398  1.114093  1.728629e+00     3A  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    51481\n",
       "2A    10576\n",
       "2B    10096\n",
       "1A       16\n",
       "1B       16\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.columns\n",
    "\n",
    "#we check the distribution of target variable\n",
    "df['QScore'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country               0\n",
       "year                  0\n",
       "country_code          0\n",
       "record                0\n",
       "crop_land         20472\n",
       "grazing_land      20472\n",
       "forest_land       20472\n",
       "fishing_ground    20473\n",
       "built_up_land     20473\n",
       "carbon            20473\n",
       "total                 9\n",
       "QScore                1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the number of missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country           0\n",
       "year              0\n",
       "country_code      0\n",
       "record            0\n",
       "crop_land         0\n",
       "grazing_land      0\n",
       "forest_land       0\n",
       "fishing_ground    0\n",
       "built_up_land     0\n",
       "carbon            0\n",
       "total             0\n",
       "QScore            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for simplicity, we will drop the rows with missing values\n",
    "df = df.dropna()\n",
    "df.isna().sum() #and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    51473\n",
       "2A      224\n",
       "1A       16\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"QScore\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    51473\n",
       "2A      240\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#An obvious change in our target variable after removing the missing values is that there are only three classes left\n",
    "#and from the distribution of the 3 classes, we can see that there is an obvious imbalance between the classes.\n",
    "#There are methods that can be applied to handle this imbalance such as oversampling and undersampling.\n",
    "#Oversampling involves increasing the data points in the class with fewer instances.\n",
    "#while undersampling involves reducing the data points in the class with more instances\n",
    "#For now, we will convert this to a binary classification problem by combining class \"2A\" and \"1A\"\n",
    "\n",
    "df[\"QScore\"] = df[\"QScore\"].replace(['1A'], '2A')\n",
    "df.QScore.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2A = df[df.QScore==\"2A\"]\n",
    "df_3A = df[df.QScore==\"3A\"].sample(350)\n",
    "data_df = df_2A.append(df_3A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    350\n",
       "2A    240\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.utils\n",
    "data_df = sklearn.utils.shuffle(data_df)\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "data_df.shape\n",
    "data_df.QScore.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    246\n",
       "2A    167\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#more processing\n",
    "data_df = data_df.drop(columns=['country_code', 'country', 'year'])\n",
    "x = data_df.drop(columns='QScore')\n",
    "y = data_df['QScore']\n",
    "\n",
    "#split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is still an imbalance in the class distribution. For this, we use SMOTE only on the training data to handle this\n",
    "\n",
    "#encode categorical variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "x_train.record = encoder.fit_transform(x_train.record)\n",
    "x_test.record = encoder.transform(x_test.record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=1)\n",
    "x_train_balanced, y_balanced = smote.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "normalised_train_df = scaler.fit_transform(x_train_balanced.drop(columns=['record']))\n",
    "normalised_train_df = pd.DataFrame(normalised_train_df, columns=x_train_balanced.drop(columns=['record']).columns)\n",
    "normalised_train_df['record'] = x_train_balanced['record']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reset_index(drop=True)\n",
    "normalised_test_df = scaler.transform(x_test.drop(columns=['record']))\n",
    "normalised_test_df = pd.DataFrame(normalised_test_df, columns=x_test.drop(columns=['record']).columns)\n",
    "normalised_test_df['record'] = x_test['record']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLogisticRegression(C= 1.0 , class_weight= None , dual= False , fit_intercept= True ,\\n intercept_scaling= 1 , l1_ratio= None , max_iter= 100 ,\\n multi_class= 'auto' , n_jobs= None , penalty= 'l2' ,\\n random_state= None , solver= 'lbfgs' , tol= 0.0001 , verbose= 0 ,\\n warm_start= False ) \\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(normalised_train_df, y_balanced)\n",
    "\n",
    "#returns=\n",
    "'''\n",
    "LogisticRegression(C= 1.0 , class_weight= None , dual= False , fit_intercept= True ,\n",
    " intercept_scaling= 1 , l1_ratio= None , max_iter= 100 ,\n",
    " multi_class= 'auto' , n_jobs= None , penalty= 'l2' ,\n",
    " random_state= None , solver= 'lbfgs' , tol= 0.0001 , verbose= 0 ,\n",
    " warm_start= False ) \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEASURING CLASSIFICATION PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51391162, 0.49661017, 0.61763155, 0.51278409, 0.44690635])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross-validation and accuracy\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(log_reg, normalised_train_df, y_balanced, cv=5, scoring='f1_macro')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39, 34],\n",
       "       [54, 50]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "new_predictions = log_reg.predict(normalised_test_df)\n",
    "cnf_mat = confusion_matrix(y_true=y_test, y_pred=new_predictions, labels=[ '2A' , '3A' ])\n",
    "cnf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=new_predictions)\n",
    "print( 'Accuracy: {}' .format(round(accuracy* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 42\n"
     ]
    }
   ],
   "source": [
    "#precision\n",
    "precision = precision_score(y_true=y_test, y_pred=new_predictions, pos_label= '2A' )\n",
    "print( 'Precision: {}' .format(round(precision* 100 ), 2 )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 53\n"
     ]
    }
   ],
   "source": [
    "#Recall\n",
    "recall = recall_score(y_true=y_test, y_pred=new_predictions, pos_label= '2A' )\n",
    "print( 'Recall: {}' .format(round(recall* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 47\n"
     ]
    }
   ],
   "source": [
    "#F1-score\n",
    "f1 = f1_score(y_true=y_test, y_pred=new_predictions, pos_label= '2A' )\n",
    "print( 'F1: {}' .format(round(f1* 100 ), 2 )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "#K-Fold Cross Validation\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "kf.split(normalised_train_df)\n",
    "f1_scores = []\n",
    "\n",
    "#run for every split\n",
    "for train_index, test_index in kf.split(normalised_train_df):\n",
    "    x_train, x_test = normalised_train_df.iloc[train_index], normalised_train_df.iloc[test_index]\n",
    "    y_train, y_test = y_balanced[train_index], y_balanced[test_index]\n",
    "    model = LogisticRegression().fit(x_train, y_train)\n",
    "    \n",
    "#save result to list\n",
    "f1_scores.append(f1_score(y_true=y_test, y_pred=model.predict(x_test), pos_label='2A')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified k-Fold Cross Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "f1_scores = []\n",
    "\n",
    "# run for every split\n",
    "for train_index, test_index in skf.split(normalised_train_df, y_balanced):\n",
    "    x_train, x_test = np.array(normalised_train_df)[train_index], np.array(normalised_train_df)[test_index]\n",
    "    y_train, y_test = y_balanced[train_index], y_balanced[test_index]\n",
    "    \n",
    "    model = LogisticRegression().fit(x_train, y_train)\n",
    "# save result to list\n",
    "f1_scores.append(f1_score(y_true=y_test, y_pred=model.predict(x_test), pos_label='2A'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave One Out Cross Validation (LOOCV)\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(LogisticRegression(), normalised_train_df, y_balanced, cv=loo, scoring='f1_macro')\n",
    "average_score = scores.mean()*100"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42588fd11209419b7c81abe23e31a1d2101f60811b02170c268e57ebb57d5d9a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
